{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6927,"databundleVersionId":45059,"sourceType":"competition"}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:54:42.360173Z","iopub.execute_input":"2025-01-20T22:54:42.360506Z","iopub.status.idle":"2025-01-20T22:54:42.367231Z","shell.execute_reply.started":"2025-01-20T22:54:42.360478Z","shell.execute_reply":"2025-01-20T22:54:42.366562Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Can be done using one for loop\nimport zipfile\n\nwith zipfile.ZipFile(\"/kaggle/input/carvana-image-masking-challenge/train.zip\") as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile(\"/kaggle/input/carvana-image-masking-challenge/train_masks.zip\") as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile(\"/kaggle/input/carvana-image-masking-challenge/train_masks.csv.zip\") as z:\n    z.extractall(\".\")\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:54:42.399899Z","iopub.execute_input":"2025-01-20T22:54:42.400090Z","iopub.status.idle":"2025-01-20T22:54:48.193609Z","shell.execute_reply.started":"2025-01-20T22:54:42.400072Z","shell.execute_reply":"2025-01-20T22:54:48.192547Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport cv2\nimport torch\nimport torch.nn as nn\nimport random\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset,DataLoader\nfrom PIL import Image\n# from torchvision.transforms import functional as F","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:54:48.195287Z","iopub.execute_input":"2025-01-20T22:54:48.195709Z","iopub.status.idle":"2025-01-20T22:54:48.201512Z","shell.execute_reply.started":"2025-01-20T22:54:48.195669Z","shell.execute_reply":"2025-01-20T22:54:48.200273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(os.listdir('/kaggle/working/train'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:54:48.203217Z","iopub.execute_input":"2025-01-20T22:54:48.203534Z","iopub.status.idle":"2025-01-20T22:54:48.218630Z","shell.execute_reply.started":"2025-01-20T22:54:48.203448Z","shell.execute_reply":"2025-01-20T22:54:48.217684Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%config Completer.use_jedi = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:54:48.219917Z","iopub.execute_input":"2025-01-20T22:54:48.220200Z","iopub.status.idle":"2025-01-20T22:54:48.233776Z","shell.execute_reply.started":"2025-01-20T22:54:48.220171Z","shell.execute_reply":"2025-01-20T22:54:48.233039Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for i in os.listdir('/kaggle/working/train'):\n#very interesting thing. I always use random number fron numpy and use for loop. Use random.choice\ni = random.choice(os.listdir('/kaggle/working/train'))\nimage = os.path.join('/kaggle/working/train',i)\nim = cv2.imread(image)\nim = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n# plt.imshow(im)\nfile = i.replace('.jpg','_mask.gif')\nmask = os.path.join('/kaggle/working/train_masks',file)\nmsk = Image.open(mask).convert('L')\n# plt.imshow(msk)\nfig,axes = plt.subplots(1,2,figsize=(12,6))\naxes[0].imshow(im)\naxes[1].imshow(msk)\n\n    # print(i)\n    # break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:54:48.234656Z","iopub.execute_input":"2025-01-20T22:54:48.234846Z","iopub.status.idle":"2025-01-20T22:54:49.113555Z","shell.execute_reply.started":"2025-01-20T22:54:48.234829Z","shell.execute_reply":"2025-01-20T22:54:49.112682Z"}},"outputs":[],"execution_count":null},{"cell_type":"raw","source":"os.chdir('/kaggle/working/')","metadata":{}},{"cell_type":"code","source":"i = random.choice(os.listdir('/kaggle/working/train'))\nimage = os.path.join('/kaggle/working/train',i)\nplt.imshow(np.array(Image.open(image).convert('RGB')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:54:49.114522Z","iopub.execute_input":"2025-01-20T22:54:49.114859Z","iopub.status.idle":"2025-01-20T22:54:49.663823Z","shell.execute_reply.started":"2025-01-20T22:54:49.114828Z","shell.execute_reply":"2025-01-20T22:54:49.663000Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(np.array(Image.open(image).convert('RGB'))/255.0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:54:49.664570Z","iopub.execute_input":"2025-01-20T22:54:49.664876Z","iopub.status.idle":"2025-01-20T22:54:50.744747Z","shell.execute_reply.started":"2025-01-20T22:54:49.664773Z","shell.execute_reply":"2025-01-20T22:54:50.743866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/working/train_masks.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:54:50.747291Z","iopub.execute_input":"2025-01-20T22:54:50.747552Z","iopub.status.idle":"2025-01-20T22:54:51.187512Z","shell.execute_reply.started":"2025-01-20T22:54:50.747531Z","shell.execute_reply":"2025-01-20T22:54:51.186791Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:54:51.189108Z","iopub.execute_input":"2025-01-20T22:54:51.189424Z","iopub.status.idle":"2025-01-20T22:54:51.197025Z","shell.execute_reply.started":"2025-01-20T22:54:51.189399Z","shell.execute_reply":"2025-01-20T22:54:51.196412Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Next steps:\n1. Dataset class\n2. Create model\n3. Train model","metadata":{}},{"cell_type":"code","source":"class CarvanaDataset(Dataset):\n    def __init__(self,image_dir,mask_dir,transform=None):\n        self.image_dir = image_dir\n        self.mask_dir = mask_dir\n        self.transform = transform\n        self.images = os.listdir(self.image_dir)\n\n    def __len__(self):\n        # return len(os.listdir(self.image_dir))\n        return len(self.images)\n\n    def __getitem__(self,idx):\n        img_path = os.path.join(self.image_dir,self.images[idx])\n        mask_path = os.path.join(self.mask_dir,self.images[idx].replace('.jpg','_mask.gif'))\n        image = np.array(Image.open(img_path).convert('RGB'),dtype=np.float32)/255.0\n        mask = np.array(Image.open(mask_path).convert('L'),dtype=np.float32)/255.0\n        # mask = mask/255.0 #Normalize mask to 0 and 1\n        mask = np.expand_dims(mask, axis=-1)\n\n        if self.transform:\n            augmentations = self.transform(image=image,mask=mask)\n            image = augmentations['image']\n            mask = augmentations['mask']\n            mask = mask.permute(2, 0, 1)\n        else:\n            image = torch.tensor(image,dtype = torch.float32).permute(2,0,1)\n            mask = torch.tensor(mask,dtype = torch.float32).unsqueeze(0)\n            \n        return image,mask\n        \n        \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:06:39.661757Z","iopub.execute_input":"2025-01-20T23:06:39.662092Z","iopub.status.idle":"2025-01-20T23:06:39.669358Z","shell.execute_reply.started":"2025-01-20T23:06:39.662064Z","shell.execute_reply":"2025-01-20T23:06:39.668221Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\ntransform_func = A.Compose([A.Resize(256,256),\n                       A.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5)),\n                       ToTensorV2()])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:06:41.904362Z","iopub.execute_input":"2025-01-20T23:06:41.904645Z","iopub.status.idle":"2025-01-20T23:06:41.909843Z","shell.execute_reply.started":"2025-01-20T23:06:41.904623Z","shell.execute_reply":"2025-01-20T23:06:41.908951Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform_func","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:06:42.613511Z","iopub.execute_input":"2025-01-20T23:06:42.613793Z","iopub.status.idle":"2025-01-20T23:06:42.618861Z","shell.execute_reply.started":"2025-01-20T23:06:42.613772Z","shell.execute_reply":"2025-01-20T23:06:42.618148Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(os.listdir('/kaggle/working/train'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:06:46.179460Z","iopub.execute_input":"2025-01-20T23:06:46.179752Z","iopub.status.idle":"2025-01-20T23:06:46.187555Z","shell.execute_reply.started":"2025-01-20T23:06:46.179731Z","shell.execute_reply":"2025-01-20T23:06:46.186719Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.chdir('/kaggle/working/')\nlist = ['train1_images','train1_masks','test1_images','test1_masks']\nfor i in list:\n    os.makedirs(os.path.join('/kaggle/working/',i),exist_ok=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:54:51.251633Z","iopub.execute_input":"2025-01-20T22:54:51.251830Z","iopub.status.idle":"2025-01-20T22:54:51.259845Z","shell.execute_reply.started":"2025-01-20T22:54:51.251811Z","shell.execute_reply":"2025-01-20T22:54:51.258982Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nk = 0\nfor i in (os.listdir('/kaggle/working/train')):\n    if k < 4500:\n        dest = (os.path.join('/kaggle/working/train',i))\n        src = '/kaggle/working/train1_images'\n        shutil.copy(dest,src)\n        mask_dest = (os.path.join('/kaggle/working/train_masks',i.replace('.jpg','_mask.gif')))\n        mask_src = '/kaggle/working/train1_masks'\n        shutil.copy(mask_dest,mask_src)\n    else:\n        dest = (os.path.join('/kaggle/working/train',i))\n        src = '/kaggle/working/test1_images'\n        shutil.copy(dest,src)\n        mask_dest = (os.path.join('/kaggle/working/train_masks',i.replace('.jpg','_mask.gif')))\n        mask_src = '/kaggle/working/test1_masks'\n        shutil.copy(mask_dest,mask_src)\n    k+=1\n        \n    # break\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:54:51.260620Z","iopub.execute_input":"2025-01-20T22:54:51.260889Z","iopub.status.idle":"2025-01-20T22:54:53.306066Z","shell.execute_reply.started":"2025-01-20T22:54:51.260870Z","shell.execute_reply":"2025-01-20T22:54:53.305412Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_dir='/kaggle/working/train'\nmask_dir='/kaggle/working/train_masks'\ntrain_data = CarvanaDataset(image_dir,mask_dir,transform=transform_func)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:06:49.898103Z","iopub.execute_input":"2025-01-20T23:06:49.898433Z","iopub.status.idle":"2025-01-20T23:06:49.904986Z","shell.execute_reply.started":"2025-01-20T23:06:49.898403Z","shell.execute_reply":"2025-01-20T23:06:49.904101Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data[0][1].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:06:50.326529Z","iopub.execute_input":"2025-01-20T23:06:50.326804Z","iopub.status.idle":"2025-01-20T23:06:50.376153Z","shell.execute_reply.started":"2025-01-20T23:06:50.326781Z","shell.execute_reply":"2025-01-20T23:06:50.375450Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# fig,ax = plt.subplots(1,2,figsize=(12,6))\n# # plt.imshow(train_data[1][1])\n# ax[0].imshow(train_data[100][0])\n# ax[1].imshow(train_data[100][1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:06:54.133245Z","iopub.execute_input":"2025-01-20T23:06:54.133582Z","iopub.status.idle":"2025-01-20T23:06:54.136923Z","shell.execute_reply.started":"2025-01-20T23:06:54.133558Z","shell.execute_reply":"2025-01-20T23:06:54.135995Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# image_dir='/kaggle/working/train'\n# mask_dir='/kaggle/working/train_masks'\ntrain_data = CarvanaDataset(image_dir='/kaggle/working/train1_images',mask_dir='/kaggle/working/train1_masks',transform=transform_func)\ntest_data = CarvanaDataset(image_dir='/kaggle/working/test1_images',mask_dir='/kaggle/working/test1_masks',transform=transform_func)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:06:54.637847Z","iopub.execute_input":"2025-01-20T23:06:54.638134Z","iopub.status.idle":"2025-01-20T23:06:54.644724Z","shell.execute_reply.started":"2025-01-20T23:06:54.638110Z","shell.execute_reply":"2025-01-20T23:06:54.644046Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = DataLoader(train_data,batch_size=4,num_workers=1,shuffle=True)\ntest_loader = DataLoader(test_data,batch_size=4,num_workers=1,shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:06:55.063767Z","iopub.execute_input":"2025-01-20T23:06:55.064084Z","iopub.status.idle":"2025-01-20T23:06:55.068839Z","shell.execute_reply.started":"2025-01-20T23:06:55.064057Z","shell.execute_reply":"2025-01-20T23:06:55.067882Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data[0][1].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:06:56.568704Z","iopub.execute_input":"2025-01-20T23:06:56.568983Z","iopub.status.idle":"2025-01-20T23:06:56.616480Z","shell.execute_reply.started":"2025-01-20T23:06:56.568962Z","shell.execute_reply":"2025-01-20T23:06:56.615705Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Model","metadata":{}},{"cell_type":"code","source":"\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DoubleConv, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\nclass UNet(nn.Module):\n    def __init__(self, in_channels=3, out_channels=1):\n        super(UNet, self).__init__()\n        \n        self.encoder1 = DoubleConv(in_channels, 64)\n        self.encoder2 = DoubleConv(64, 128)\n        self.encoder3 = DoubleConv(128, 256)\n        self.encoder4 = DoubleConv(256, 512)\n        \n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        self.bottleneck = DoubleConv(512, 1024)\n        \n        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n        self.decoder4 = DoubleConv(1024, 512)\n        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n        self.decoder3 = DoubleConv(512, 256)\n        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n        self.decoder2 = DoubleConv(256, 128)\n        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n        self.decoder1 = DoubleConv(128, 64)\n        \n        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n\n    def forward(self, x):\n        enc1 = self.encoder1(x)\n        enc2 = self.encoder2(self.pool(enc1))\n        enc3 = self.encoder3(self.pool(enc2))\n        enc4 = self.encoder4(self.pool(enc3))\n        \n        bottleneck = self.bottleneck(self.pool(enc4))\n        \n        dec4 = self.upconv4(bottleneck)\n        dec4 = torch.cat((enc4, dec4), dim=1)\n        dec4 = self.decoder4(dec4)\n        \n        dec3 = self.upconv3(dec4)\n        dec3 = torch.cat((enc3, dec3), dim=1)\n        dec3 = self.decoder3(dec3)\n        \n        dec2 = self.upconv2(dec3)\n        dec2 = torch.cat((enc2, dec2), dim=1)\n        dec2 = self.decoder2(dec2)\n        \n        dec1 = self.upconv1(dec2)\n        dec1 = torch.cat((enc1, dec1), dim=1)\n        dec1 = self.decoder1(dec1)\n        \n        return self.final_conv(dec1)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:04:26.419418Z","iopub.execute_input":"2025-01-20T23:04:26.419817Z","iopub.status.idle":"2025-01-20T23:04:26.439483Z","shell.execute_reply.started":"2025-01-20T23:04:26.419785Z","shell.execute_reply":"2025-01-20T23:04:26.438510Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:02:02.957669Z","iopub.execute_input":"2025-01-20T23:02:02.957997Z","iopub.status.idle":"2025-01-20T23:02:03.043249Z","shell.execute_reply.started":"2025-01-20T23:02:02.957968Z","shell.execute_reply":"2025-01-20T23:02:03.042471Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = UNet().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:04:31.364899Z","iopub.execute_input":"2025-01-20T23:04:31.365226Z","iopub.status.idle":"2025-01-20T23:04:31.637509Z","shell.execute_reply.started":"2025-01-20T23:04:31.365195Z","shell.execute_reply":"2025-01-20T23:04:31.636842Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_input = torch.randn(1, 3, 256, 256)  # Batch size of 1, 3 channels, 256x256 image\noutput = model(sample_input.to(device))\nprint(output.shape)  # Output shape should be [1, 1, 256, 256]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:04:32.259136Z","iopub.execute_input":"2025-01-20T23:04:32.259580Z","iopub.status.idle":"2025-01-20T23:04:32.273196Z","shell.execute_reply.started":"2025-01-20T23:04:32.259553Z","shell.execute_reply":"2025-01-20T23:04:32.272557Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Hyperparam\nloss_fn = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr = 1e-04)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:04:33.997508Z","iopub.execute_input":"2025-01-20T23:04:33.997790Z","iopub.status.idle":"2025-01-20T23:04:34.002163Z","shell.execute_reply.started":"2025-01-20T23:04:33.997768Z","shell.execute_reply":"2025-01-20T23:04:34.001415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\n\nnum_epochs = 50\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0\n    for images, masks in tqdm(train_loader):\n        images = images.to(device)  # Move to GPU if available\n        masks = masks.to(device)\n        \n        # Forward pass\n        outputs = model(images)\n        # outputs=outputs.squeeze(0)\n        loss = loss_fn(outputs, masks)\n        \n        # Backpropagation and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n    \n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss/len(train_loader):.4f}\")\n    \n    # Scheduler step (optional)\n    # scheduler.step(train_loss)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T23:07:00.677010Z","iopub.execute_input":"2025-01-20T23:07:00.677289Z","execution_failed":"2025-01-21T00:49:45.034Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), 'carvana_unet_model.pth')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-21T00:49:45.035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-20T22:54:53.860686Z","iopub.status.idle":"2025-01-20T22:54:53.861075Z","shell.execute_reply":"2025-01-20T22:54:53.860903Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}